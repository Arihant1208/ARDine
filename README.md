# AR-Dine: Interactive Menu & Ordering

An AI-powered AR menu experience for restaurants with separate views for customers and owners. Fully containerized, platform-agnostic architecture deployable on Azure, AWS, or GCP.

## ğŸ“ Project Structure

```
ARDine/
â”œâ”€â”€ src/                      # Frontend source code
â”‚   â”œâ”€â”€ features/            # Feature-based modules
â”‚   â”‚   â”œâ”€â”€ auth/           # Authentication (Login/Signup)
â”‚   â”‚   â”œâ”€â”€ customer/       # Customer views (Menu, AR, Cart)
â”‚   â”‚   â”œâ”€â”€ owner/          # Owner dashboard (Orders, Menu Management)
â”‚   â”‚   â””â”€â”€ landing/        # Landing page
â”‚   â”œâ”€â”€ shared/             # Shared resources
â”‚   â”‚   â”œâ”€â”€ components/     # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ layout/         # Layout components (Header, etc.)
â”‚   â”‚   â”œâ”€â”€ services/       # API clients
â”‚   â”‚   â””â”€â”€ types.ts        # TypeScript types
â”‚   â”œâ”€â”€ stores/             # Zustand state management
â”‚   â””â”€â”€ App.tsx
â”œâ”€â”€ backend/                 # Express backend + worker
â”‚   â”œâ”€â”€ db/                 # Database setup & seed
â”‚   â”œâ”€â”€ menuController.ts   # Image â†’ AI â†’ MinIO â†’ BullMQ enqueue
â”‚   â”œâ”€â”€ orderController.ts  # Order CRUD + status transitions
â”‚   â”œâ”€â”€ server.ts           # Express API with helmet, rate limiting
â”‚   â”œâ”€â”€ worker.ts           # BullMQ consumer for 3D model generation
â”‚   â”œâ”€â”€ queue.ts            # Shared queue config & job types
â”‚   â”œâ”€â”€ storageClient.ts    # S3-compatible blob storage client
â”‚   â”œâ”€â”€ scannerClient.ts    # ClamAV malware scanning client
â”‚   â”œâ”€â”€ instrumentation.ts  # OpenTelemetry auto-instrumentation
â”‚   â”œâ”€â”€ aiClient.ts         # Gemini AI client factory
â”‚   â””â”€â”€ validators.ts       # Magic-byte + size validation
â”œâ”€â”€ database/               # Data-access boundary
â”‚   â”œâ”€â”€ dbClient.ts        # PostgreSQL client (pg Pool)
â”‚   â””â”€â”€ repositories.ts    # Repository pattern CRUD layer
â”œâ”€â”€ docker/                 # Container configuration
â”‚   â”œâ”€â”€ nginx.conf         # Frontend reverse proxy config
â”‚   â””â”€â”€ otel-collector-config.yaml
â”œâ”€â”€ helm/                   # Kubernetes Helm chart
â”‚   â””â”€â”€ ardine/
â”‚       â”œâ”€â”€ Chart.yaml
â”‚       â”œâ”€â”€ values.yaml
â”‚       â””â”€â”€ templates/     # Deployment, Service, Ingress, etc.
â”œâ”€â”€ Dockerfile.frontend     # Multi-stage: Vite build â†’ Nginx
â”œâ”€â”€ Dockerfile.backend      # Node 22 alpine â†’ Express API
â”œâ”€â”€ Dockerfile.worker       # Node 22 alpine â†’ BullMQ consumer
â”œâ”€â”€ docker-compose.yml      # Local orchestration (8 services)
â””â”€â”€ .env.example           # All environment variables documented
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚â”€â”€â”€â”€â–¶â”‚   Backend    â”‚â”€â”€â”€â”€â–¶â”‚    Worker    â”‚
â”‚  (Nginx:80)  â”‚     â”‚(Express:4000)â”‚     â”‚  (BullMQ)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
              â–¼             â–¼                     â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚PostgreSQLâ”‚  â”‚  Redis   â”‚         â”‚  MinIO   â”‚
        â”‚  :5432   â”‚  â”‚  :6379   â”‚         â”‚(S3):9000 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
                      â”‚  OTel    â”‚         â”‚  ClamAV  â”‚
                      â”‚Collector â”‚         â”‚  :3310   â”‚
                      â”‚:4317/4318â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **React SPA** â†’ calls `src/shared/services/api.ts` â†’ Nginx reverse-proxies `/api` to backend
2. **Express API** â†’ validates input â†’ scans images with ClamAV â†’ uploads to MinIO (S3-compatible) â†’ analyzes with Gemini AI â†’ enqueues BullMQ job
3. **Worker** â†’ picks up job from Redis â†’ simulates/generates 3D model â†’ scans `.glb` with ClamAV â†’ uploads to MinIO â†’ updates PostgreSQL
4. **Frontend polls** `/api/users/:id/menu` every 5s until `modelGenerationStatus === 'ready'`
5. **AR Viewer** â†’ renders `arModelUrl` (MinIO URL proxied via `/storage`) in `<model-viewer>` web component

### Platform-Agnostic Design

Every component uses open standards â€” **no cloud vendor lock-in**:

| Component | Local (Docker Compose) | Azure | AWS | GCP |
|-----------|----------------------|-------|-----|-----|
| Database | `postgres:16-alpine` | Azure DB for PostgreSQL | RDS / Aurora | Cloud SQL |
| Queue | `redis:7-alpine` | Azure Cache for Redis | ElastiCache | Memorystore |
| Blob Storage | `minio/minio` (S3 API) | Azure Blob (S3 gateway) | S3 | Cloud Storage |
| Malware Scan | `clamav/clamav` | Defender for Storage | GuardDuty | SCC |
| Observability | OTel Collector | Azure Monitor | X-Ray | Cloud Trace |
| Orchestration | Docker Compose | AKS | EKS | GKE |

Only the **connection strings / env vars** change between environments â€” zero code changes.

## ğŸš€ Getting Started

### Option 1: Docker Compose (Recommended)

Run the entire stack locally with a single command:

```bash
# 1. Copy and configure environment variables
cp .env.example .env
# Edit .env â€” at minimum set GEMINI_API_KEY

# 2. Start all 8 containers
docker compose up --build

# 3. Access the app
#    Frontend:       http://localhost
#    Backend API:    http://localhost:4000
#    MinIO Console:  http://localhost:9001 (minioadmin / minioadmin)
#    PostgreSQL:     localhost:5432

# Scale workers for parallel 3D generation
docker compose up --scale worker=3

# Tear down
docker compose down
```

**What starts:** Frontend (Nginx), Backend (Express), Worker (BullMQ), PostgreSQL, Redis, MinIO, ClamAV, OpenTelemetry Collector.

### Option 2: Local Development (without Docker)

For iterating on code without rebuilding containers:

```bash
# Prerequisites: Node.js 22+, running PostgreSQL, Redis, MinIO instances

npm install

# Set up environment
cp .env.example .env.local
# Edit .env.local with local connection strings

# Terminal 1: Frontend (Vite dev server with HMR)
npm run dev

# Terminal 2: Backend API
npm run backend:dev

# Terminal 3: 3D Worker
npm run worker:dev
```

| Service | URL |
|---------|-----|
| Frontend | http://localhost:3000 |
| Backend API | http://localhost:4000 |

### Environment Variables

All variables are documented in `.env.example`. Key ones:

| Variable | Required | Description |
|----------|----------|-------------|
| `GEMINI_API_KEY` | Yes | Google Gemini API key (server-side only) |
| `DATABASE_URL` | Yes | PostgreSQL connection string |
| `REDIS_URL` | Yes | Redis connection string for BullMQ |
| `S3_ENDPOINT` | Yes | MinIO / S3-compatible endpoint |
| `S3_ACCESS_KEY` / `S3_SECRET_KEY` | Yes | Blob storage credentials |
| `CLAMAV_HOST` | No | ClamAV daemon host (default: `clamav`) |
| `STORAGE_PUBLIC_URL` | No | Public base URL for stored files |
| `OTEL_EXPORTER_OTLP_ENDPOINT` | No | OpenTelemetry collector endpoint |

## ğŸ³ Container Architecture

### Services (docker-compose.yml)

| Service | Image | Ports | Purpose |
|---------|-------|-------|---------|
| `frontend` | `Dockerfile.frontend` | `80` | Nginx SPA + reverse proxy |
| `backend` | `Dockerfile.backend` | `4000` | Express API server |
| `worker` | `Dockerfile.worker` | â€” | BullMQ 3D generation consumer |
| `db` | `postgres:16-alpine` | `5432` | Persistent relational data |
| `redis` | `redis:7-alpine` | `6379` | Job queue (BullMQ) broker |
| `minio` | `minio/minio` | `9000` / `9001` | S3-compatible blob storage |
| `clamav` | `clamav/clamav:stable` | `3310` | Malware scanning daemon |
| `otel-collector` | `otel/opentelemetry-collector-contrib` | `4317` / `4318` | Telemetry collection |

### Blob Storage (MinIO â€” S3-compatible)

Two buckets are auto-created on startup:
- **`dish-images`** â€” 2D dish photos (uploaded during menu analysis)
- **`dish-models`** â€” `.glb` 3D model files (generated by worker)

The `storageClient.ts` uses `@aws-sdk/client-s3` â€” works unchanged against MinIO, AWS S3, GCS (HMAC), or Azure Blob (S3 gateway).

### Message Queue (Redis + BullMQ)

The 3D model generation pipeline is decoupled from the API:

1. `POST /api/users/:id/menu/analyze` â†’ saves dish â†’ enqueues `model-generation` job
2. Worker picks up job â†’ generates model â†’ scans with ClamAV â†’ uploads `.glb` â†’ updates DB
3. Frontend polls until `modelGenerationStatus === 'ready'`

Jobs support: 3 retries with exponential backoff, rate limiting (10/min), progress tracking.

### Security Scanning (ClamAV)

All user-uploaded files are scanned **before** being written to blob storage:
- 2D images: scanned in the `/analyze` API endpoint
- 3D models: scanned in the worker before upload

If ClamAV is unavailable, behavior is configurable via `CLAMAV_REQUIRED=true` (fail hard) or default (warn and skip).

### Observability (OpenTelemetry)

Auto-instrumented traces/metrics for Express, `pg`, `ioredis`, and HTTP calls. The collector config (`docker/otel-collector-config.yaml`) exports to console by default â€” uncomment the relevant exporter for production:

```yaml
# Azure Monitor:
# azuremonitor:
#   connection_string: ${APPLICATIONINSIGHTS_CONNECTION_STRING}

# AWS X-Ray:
# awsxray:
#   region: ${AWS_REGION}

# GCP Cloud Trace:
# googlecloud:
#   project: ${GCP_PROJECT_ID}
```

## â˜¸ï¸ Kubernetes Deployment (Helm)

A Helm chart is provided in `helm/ardine/` for deploying to any managed Kubernetes cluster (AKS, EKS, GKE).

```bash
# Build and push images to your OCI registry
docker build -f Dockerfile.frontend -t ghcr.io/your-org/ardine-frontend:latest .
docker build -f Dockerfile.backend  -t ghcr.io/your-org/ardine-backend:latest .
docker build -f Dockerfile.worker   -t ghcr.io/your-org/ardine-worker:latest .

# Deploy to cluster
helm install ardine ./helm/ardine \
  --set secrets.geminiApiKey=YOUR_KEY \
  --set image.frontend.repository=ghcr.io/your-org/ardine-frontend \
  --set image.backend.repository=ghcr.io/your-org/ardine-backend \
  --set image.worker.repository=ghcr.io/your-org/ardine-worker
```

### Using Managed Services (Production)

Disable containerized infra and point to managed equivalents:

```yaml
# values.yaml overrides for production
postgresql:
  enabled: false
externalDatabase:
  host: your-db.postgres.database.azure.com
  password: xxx

redis:
  enabled: false
externalRedis:
  host: your-cache.redis.cache.windows.net

minio:
  enabled: false
externalStorage:
  endpoint: https://s3.amazonaws.com
  accessKey: xxx
  secretKey: xxx
  forcePathStyle: false
```

## ğŸ› ï¸ Development

### Available Scripts

| Script | Command | Description |
|--------|---------|-------------|
| `npm run dev` | `vite` | Frontend dev server (port 3000) |
| `npm run backend:dev` | `tsx backend/server.ts` | Backend API server (port 4000) |
| `npm run worker:dev` | `tsx backend/worker.ts` | 3D model worker |
| `npm run build` | `vite build` | Production frontend build |
| `npm run typecheck` | `tsc --noEmit` | TypeScript type checking |
| `npm run verify` | typecheck + build | CI verification |
| `npm run db:setup` | `tsx backend/db/setup.ts` | Apply SQL schema to PostgreSQL |
| `npm run docker:up` | `docker compose up --build` | Start all containers |
| `npm run docker:down` | `docker compose down` | Stop all containers |
| `npm run docker:logs` | `docker compose logs -f` | Tail all container logs |

### Code Organization

- **Features are isolated**: Each feature (auth, customer, owner) has its own directory
- **Shared code is centralized**: Common components, types, and services in `src/shared/`
- **State is managed globally**: Zustand stores provide global state management
- **Backend is modular**: Controllers â†’ Validators â†’ Repositories â†’ DB Client
- **Worker is decoupled**: 3D generation runs in a separate container via BullMQ
- **Storage is abstracted**: S3-compatible client works with MinIO, AWS S3, GCS, Azure Blob

### Security Measures

| Layer | Implementation |
|-------|---------------|
| HTTP headers | `helmet` middleware (CSP, X-Frame-Options, etc.) |
| Rate limiting | `express-rate-limit` â€” 200 req/15min general, 20 req/15min for AI |
| Image validation | Magic-byte verification (PNG/JPEG/WebP), 5 MB size cap |
| Malware scanning | ClamAV INSTREAM protocol on all uploads |
| SQL injection | Parameterized queries throughout `dbClient.ts` |
| Secrets | Server-side only â€” never shipped to browser bundles |

## ğŸ”‘ Key Features

### For Customers
- Browse AR-enabled menu
- View 3D models of dishes in augmented reality
- Add items to cart
- Place orders with multiple payment methods (UPI, Card, Cash, Wallet)

### For Owners
- Upload menu photos â€” AI generates dish metadata + 3D generation prompt
- Track 3D model generation progress in real-time
- Manage restaurant configuration
- View live orders dashboard with status transitions
- Generate QR codes for tables

## ğŸ“ Notes

- **Database**: PostgreSQL with parameterized queries (previously in-memory Maps)
- **AI**: Google Gemini API for dish photo analysis (API key-based, works from any cloud)
- **3D Models**: Generation pipeline runs in a separate worker container via BullMQ queue. Currently uses a placeholder model â€” replace `fetchPlaceholderModel()` in `backend/worker.ts` with a real pipeline (Shap-E, TripoSR, etc.)
- **Auth**: Basic email/password â€” implement proper JWT/OAuth for production
- **ClamAV cold start**: Takes ~60â€“120s on first boot to download virus definitions. The health check has a `start_period` of 120s

## ğŸ¤ Contributing

1. Create a feature branch
2. Make your changes
3. Run `npm run verify` (typecheck + build)
4. Run `docker compose up --build` to validate containers
5. Submit a pull request

## ğŸ“„ License

MIT
